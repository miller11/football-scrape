{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os.path\n",
    "\n",
    "# Make array of just team link\n",
    "teams = []\n",
    "\n",
    "# Pull in teams file\n",
    "path = r\"files\"\n",
    "\n",
    "with open(os.path.join(path, 'teams.csv'), 'r') as readFile:\n",
    "    reader = csv.reader(readFile)\n",
    "    next(reader)  # Skip header row\n",
    "    for row in reader:\n",
    "        teams.append(row[1])\n",
    "        \n",
    "readFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team Year files complete\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define base url\n",
    "baseUrl = 'https://www.pro-football-reference.com'\n",
    "\n",
    "# Iterate teams and get each team page\n",
    "for team in teams:\n",
    "    team_code = team.split('/')[2]\n",
    "        \n",
    "    # Define the output file in the teams dir\n",
    "    with open(os.path.join(path, 'teams', team_code + '.csv'), 'w') as writeFile:\n",
    "        writer = csv.writer(writeFile)\n",
    "    \n",
    "        # Get the individual team\n",
    "        r = requests.get(baseUrl + team)\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    \n",
    "        # Pull the headers from the table\n",
    "        team_table = soup.find('table', attrs={'id':'team_index'})\n",
    "        header_rows = team_table.find('thead').find_all('tr', attrs={'class': None})\n",
    "            \n",
    "        # Structure the header data\n",
    "        header_data = []\n",
    "        cols = header_rows[0].find_all('th')\n",
    "        cols = [ele.text.strip().encode('utf-8') for ele in cols]\n",
    "        cols.insert(1, 'Tm Link') # Add team link header column \n",
    "        header_data.append(cols)\n",
    "\n",
    "        # Write headers to the file       \n",
    "        writer.writerows(header_data)\n",
    "        \n",
    "        # Pull all the team data and write to file\n",
    "        table_rows = team_table.find('tbody').find_all('tr', attrs={'class': None})\n",
    "        \n",
    "        # Team Data\n",
    "        team_year_data = []\n",
    "\n",
    "        for row in table_rows:\n",
    "            cols = row.find_all('th')\n",
    "            team_year = cols[0].text.strip()\n",
    "            team_link = cols[0].find('a')['href']\n",
    "            cols = row.find_all('td')\n",
    "            cols = [ele.text.strip() for ele in cols]\n",
    "            cols.insert(0, team_year) # Add team name\n",
    "            cols.insert(1, team_link) # Add team link\n",
    "            team_year_data.append(cols)\n",
    "        \n",
    "        # Write data rows to the file\n",
    "        writer.writerows(team_year_data)\n",
    "\n",
    "    # Close the writer\n",
    "    writeFile.close()\n",
    "    \n",
    "print(\"Team Year files complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
